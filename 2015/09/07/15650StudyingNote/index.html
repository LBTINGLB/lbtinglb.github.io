<!DOCTYPE html>
<html lang="en,zh-Hanz,default">
    

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?ff152264e7864a4f4c07a049eae5646e";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

<head>
    <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="LBTING&#39; Blog">
    <title>15650StudyingNote - LBTING&#39; Blog</title>
    <meta name="author" content="LBTING">
    <meta name="description" content="LBTING&#39; Blog">
    <link rel="icon" href="/assets/images/null">
    
        <link rel="alternative" type="application/atom+xml" title="RSS" href="atom.xml">
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/style.min.css">
    <!--STYLES END-->
    
    
<script type="text/javascript">
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?ff152264e7864a4f4c07a049eae5646e";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

</script>

</head>

    <body>
        <div id="blog">
            <header id="header" data-behavior="1">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <h1 class="header-title">
        <a class="header-title-link" href="http://lbting.com">LBTING&#39; Blog</a>
    </h1>
    
        <a class="header-right-picture" href="/#about">
            <img class="header-picture" src="/assets/images/42.jpg"/>
        </a>
    
</header>
            <nav id="sidebar" data-behavior="1">
    
    <div class="sidebar-profile">
        <a href="/#about">
            
            <img class="sidebar-profile-picture" src="/assets/images/42.jpg"/>
            
        </a>
        <span class="sidebar-profile-name">LBTING</span>
    </div>
    
    
    <ul class="sidebar-buttons">
        
        <li class="sidebar-button">
            
                <a  class="sidebar-button-link " href="/">
            
                    <i class="sidebar-button-icon fa fa-lg fa-home"></i>
                    <span class="sidebar-button-desc">Home</span>
                </a>
        </li>
        
        <li class="sidebar-button">
            
                <a  class="sidebar-button-link " href="/all-categories">
            
                    <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
                    <span class="sidebar-button-desc">Categories</span>
                </a>
        </li>
        
        <li class="sidebar-button">
            
                <a  class="sidebar-button-link " href="/all-tags">
            
                    <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
                    <span class="sidebar-button-desc">Tags</span>
                </a>
        </li>
        
        <li class="sidebar-button">
            
                <a  class="sidebar-button-link st-search-show-outputs" href="/#search">
            
                    <i class="sidebar-button-icon fa fa-lg fa-search"></i>
                    <span class="sidebar-button-desc">Search</span>
                </a>
        </li>
        
        <li class="sidebar-button">
            
                <a  class="sidebar-button-link " href="/#about">
            
                    <i class="sidebar-button-icon fa fa-lg fa-street-view"></i>
                    <span class="sidebar-button-desc">About me</span>
                </a>
        </li>
        
        <li class="sidebar-button">
            
                <a  class="sidebar-button-link " href="http://blog.blaulan.com/" target="_blank">
            
                    <i class="sidebar-button-icon fa fa-lg fa-beer"></i>
                    <span class="sidebar-button-desc">Eric</span>
                </a>
        </li>
        
    </ul>
    
    <ul class="sidebar-buttons">
        
        <li class="sidebar-button">
            
                <a  class="sidebar-button-link " href="https://github.com/lbtinglb/lbtinglb.github.io" target="_blank">
            
                    <i class="sidebar-button-icon fa fa-lg fa-github"></i>
                    <span class="sidebar-button-desc">GitHub</span>
                </a>
        </li>
        
    </ul>
    
    <ul class="sidebar-buttons">
        
        <li class="sidebar-button">
            
                <a  class="sidebar-button-link " href="/atom.xml">
            
                    <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
                    <span class="sidebar-button-desc">RSS</span>
                </a>
        </li>
        
    </ul>
    
</nav>
            <div id="main" data-behavior="1">
                
<article class="post" itemscope itemType="http://schema.org/BlogPosting">
    
        <div class="post-header main-content-wrap">
    
        <h1 class="post-title" itemprop="headline">15650StudyingNote</h1>
    
    <div class="post-meta">
    <time  itemprop="datePublished" content="Mon Sep 07 2015 00:20:46 GMT-0400">
        Sep 07, 2015
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/CMU/">CMU</a>, <a class="category-link" href="/categories/CMU/technique/">technique</a>


    
</div>
</div>
    
    <div class="post-content markdown main-content-wrap" itemprop="articleBody">
        <p>Studying notes when taking this lesson.<br><a id="more"></a></p>
<h1 id="15650-algorithm-design-and-advanced-data-structure"><a href="#15650-Algorithm-Design-and-Advanced-Data-Structure" class="headerlink" title="15650 Algorithm Design and Advanced Data Structure"></a>15650 Algorithm Design and Advanced Data Structure</h1><!-- toc -->
<ul>
<li><a href="#week-1">Week 1</a><ul>
<li><a href="#lec00-introduction">lec00 Introduction</a></li>
<li><a href="#lec01-minimum-spanning-trees">Lec01 Minimum Spanning Trees</a></li>
<li><a href="#lec02-kruskals-mst-algorithm-union-find-data-structures">Lec02 Kruskals&#x2019; MST algorithm &amp; Union-Find Data Structures</a></li>
<li><a href="#lec03-approximation-algorithms-i-traveling-salesman">Lec03 Approximation Algorithms, I: Traveling Salesman</a></li>
<li><a href="#lec04-data-structures-for-minimum-spanning-trees-graphs-heaps">lec04 Data Structures for Minimum Spanning Trees: Graphs &amp; Heaps</a></li>
<li><a href="#lec05-clustering-with-minimum-spanning-tree">Lec05 Clustering with minimum Spanning Tree</a></li>
<li><a href="#lec06-asymptotic-analysis">Lec06 Asymptotic Analysis</a></li>
<li><a href="#lec07-graph-traversals">Lec07 Graph Traversals</a></li>
<li><a href="#lec08-applications-of-dfs-and-bfs">Lec08 Applications of DFS and BFS</a></li>
<li><a href="#lec09-applications-of-shortest-paths-and-a">Lec09 Applications of Shortest paths and A*</a></li>
<li><a href="#lec10-shortest-paths-in-a-graph">Lec10 Shortest Paths in a Graph</a></li>
<li><a href="#lec11-minimum-spanning-arborescences">Lec11 Minimum Spanning Arborescences</a></li>
<li><a href="#lec12-shortest-paths-with-negative-weights">Lec12 Shortest paths with Negative Weights</a></li>
<li><a href="#lec13-skip-lists">Lec13 Skip Lists</a></li>
</ul>
<ul>
<li><a href="#lecture-14-splay-trees">Lecture 14 Splay Trees</a></li>
<li><a href="#lecture-15-b-trees">lecture 15 B-Trees</a></li>
<li><a href="#lecture-16-suffix-trees">lecture 16 Suffix trees</a></li>
<li><a href="#lecture-17-dynamic-programming-subset-sum-knapsack">lecture 17 Dynamic Programming: Subset Sum &amp; Knapsack</a></li>
<li><a href="#lecture-18-more-dynamic-programming-examples">lecture 18 More Dynamic Programming Examples</a></li>
<li><a href="#lecture-19-string-comparison">lecture 19 String Comparison</a></li>
<li><a href="#lecture-20-rna-folding">lecture 20 RNA Folding</a></li>
<li><a href="#lecture-21-network-flows">lecture 21 Network Flows</a></li>
<li><a href="#lecture-21-maximum-bipartite-matching">lecture 21 Maximum Bipartite Matching</a></li>
<li><a href="#lecture-22-image-segmentation">lecture 22 image Segmentation</a></li>
<li><a href="#lecture-23-max-flow-extensions">lecture 23 Max-flow extensions</a></li>
<li><a href="#lecture-24-linear-programming">lecture 24 linear programming</a></li>
<li><a href="#lecture-25-the-simplex-algorithm">lecture 25 The simplex Algorithm</a></li>
<li><a href="#lecture-26-the-classes-p-and-np">lecture 26 The classes P and NP</a></li>
<li><a href="#lecture-27-reductions-np-completeness">lecture 27 Reductions &amp; NP-completeness</a></li>
<li><a href="#lecture-28-satcoloring-hamiltonian-cycle-tsp">lecture 28 SAT,Coloring, Hamiltonian Cycle, TSP</a></li>
<li><a href="#lecture-29-np-completeness-of-3-dimensional-matching-and-subset-sum">lecture 29 NP-completeness of 3 Dimensional Matching and Subset Sum</a></li>
<li><a href="#lecture-30-randomized-mincut">lecture 30 Randomized Mincut</a></li>
<li><a href="#lecture-31-approximation-algorithms">lecture 31 approximation algorithms</a></li>
<li><a href="#final-examination-preparation">final examination preparation</a></li>
<li><a href="#other-stuff-learned-by-myself">other stuff learned by myself</a></li>
</ul>
</li>
<li><a href="#red-black-tree-map-in-c">Red black tree &amp; map in C++</a></li>
</ul>
<!-- tocstop -->
<h2 id="week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h2><h3 id="lec00-introduction"><a href="#lec00-Introduction" class="headerlink" title="lec00 Introduction"></a>lec00 Introduction</h3><blockquote>
<ul>
<li>Analysi of Algorithms<ul>
<li>Prove <strong>correctness</strong></li>
<li>Discuss hwo to <strong>implement</strong></li>
<li>Prove <strong>worst-case running time</strong></li>
<li>Prove no algorithm can do better</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="lec01-minimum-spanning-trees"><a href="#Lec01-Minimum-Spanning-Trees" class="headerlink" title="Lec01 Minimum Spanning Trees"></a>Lec01 Minimum Spanning Trees</h3><blockquote>
<ul>
<li>Graph:<ul>
<li>specify pairwise relationships between objects</li>
</ul>
</li>
<li><strong>undirected Graph</strong> G = (V,E):<ul>
<li>V is a set of nodes, aka vertices</li>
<li>E is a set of two-element subsets of V.</li>
<li>A graph is <strong>directed</strong> if E is a set of ordered pairs(u,v), u,v&#x2208;V.</li>
</ul>
</li>
<li>Definition of <strong>subgraph</strong>: P5</li>
<li><strong>Connected Component</strong>: a maximal connected subgraph</li>
<li>Trees:<ul>
<li>Cycle:<ul>
<li>A <code>cycle</code> of a graph G = (V,E) is a sequence of distinct vertices V_1,&#x2026;.,V_k&#x2208;V such that {v_i,vi+1}&#x2208;E for all i = 1,&#x2026;, k and {V_k,v_1}&#x2208;E.(&#x76F8;&#x90BB;&#x70B9;&#x5FC5;&#x8FDE;&#x63A5;)</li>
</ul>
</li>
<li>A graph G is a tree if it&#x2019;s connected and contains no cycles.</li>
</ul>
</li>
<li>The <strong>Minimum Spanning Tree</strong> problem<ul>
<li>given <em>undirected</em> graph G with vertices for each of n objects; non-negative weights d(u,v)= cost of using edge {u,v}.</li>
<li>find the subgraph T that connects all vertices and <em>minimizes</em> the overall cost</li>
<li>T will be a <em>Tree</em><ul>
<li>reason: if There is a cycle, we could remove any edge on the cycle to get a new subgraph T&#x2019; with smaller cost (T&#x2019;).</li>
</ul>
</li>
</ul>
</li>
<li>Prim&#x2019;s MST algorithm<br>  step 1:<pre><code>Given graph G = (V,E), select an arbitrary vertex s &#x2208; V and
</code></pre>let T be a &#x201C;tree&#x201D; that contains only s.<br>  step 2:<br>  Repeat the following |V| - 1 times: (deal with all the remaining nodes)<pre><code>Add to T the lowest-cost edge fu; vg where u &#x2208; T and v &#x2209; T.
</code></pre></li>
<li>Further study on MST:</li>
<li>Thoerem following statements are equivalent:<ul>
<li>T is a tree;</li>
<li>T contains no cycles and n-1 edges</li>
<li>T is connected and has n-1 edges</li>
<li>T is connected and removing any edge disconnects it.</li>
<li>Any two nodes in T are connected by exactly 1 path</li>
<li>T is acyclic, and adding any new edge creates exactly one cycle.</li>
</ul>
</li>
<li>Assumption: we assume no two edges in G have the same edge cost.</li>
<li>Cut Property<ul>
<li>Let S be a subset of nodes,with |S|&gt;1 and |S| &lt; |V|. Every MST contains the edge e = {v,w};wg with v&#x2208;S and w &#x2208;V -S that has minimum weight.</li>
<li>correstness:<ul>
<li>At termination, Prim&#x2019;s algorithm returns a subgraph T that is a minimum spanning tree.</li>
</ul>
</li>
<li>prove that Prim&#x2019;s algorithm only adds edges that are in the MST</li>
</ul>
</li>
<li>Prim&#x2019;s algorithm:<ul>
<li>used to calculate MST.</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="lec02-kruskals-mst-algorithm-union-find-data-structures"><a href="#Lec02-Kruskals&#x2019;-MST-algorithm-amp-Union-Find-Data-Structures" class="headerlink" title="Lec02 Kruskals&#x2019; MST algorithm &amp; Union-Find Data Structures"></a>Lec02 Kruskals&#x2019; MST algorithm &amp; Union-Find Data Structures</h3><blockquote>
<ul>
<li>Greedy MSP rules:<ol>
<li>Starting with any root node, add the frontier edge with the smallest weight.(<strong>Prim&#x2019;s Algorithm</strong>)</li>
<li>Add edges in increasing weight, skipping those whose addition would create a cycle.(<strong>Kruskal&#x2019;s Algorithm</strong>)</li>
<li>Start with all edges, remove them in decreasing order of weight,skipping those whose removal would disconnect the graph.(<strong>&#x201C;Reverse-Delete&#x201D; Algorithm</strong>)</li>
</ol>
</li>
<li>Prim&#x2019;s Algorithm<ul>
<li>Prim&#x2019;s algorithm produces a MST</li>
</ul>
</li>
<li>Cycle Property<ul>
<li>Let C be a cycle in G. Let e = (u,v) be the edge with maximum weight on C. <strong>Then e is not in any MST of G</strong>.</li>
</ul>
</li>
<li>MST Propery Summary:<ul>
<li><code>Cut Property</code>: The smallest edge crossing any cut must be in all MSTs.</li>
<li><code>Cycle Property</code>: The largest edge on any cycle is never in any MST.</li>
</ul>
</li>
<li>&#x201C;Reverse-Delete&#x201D; Algorithm:<ul>
<li>produces a MST: because removing e won&#x2019;t disconnect the graph ,there must be another path between u and v.(removing the largest cycle)</li>
</ul>
</li>
<li>Kruskal&#x2019;s Algorithm<ul>
<li>Add edges in increasing weight, skipping those whose addition would create a cycle.(So you keep connecting the minimum edge in the whole graph)</li>
<li>produces a MST: think cut property.</li>
<li>hwo to check if adding an edge {u,v}creates a cycle:<ul>
<li>would create a cycle if u and v are already in the same component</li>
<li>we start with a component for each node</li>
<li>Components merge when we add an edge </li>
<li>Need a way to: check if u and v are in same component and<br>to merge two components into one.</li>
</ul>
</li>
<li>running time: |E|log|V|</li>
</ul>
</li>
<li>Union-Find Data Structure<ul>
<li>runing time: 2klog2(2k)</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="lec03-approximation-algorithms-i-traveling-salesman"><a href="#Lec03-Approximation-Algorithms-I-Traveling-Salesman" class="headerlink" title="Lec03 Approximation Algorithms, I: Traveling Salesman"></a>Lec03 Approximation Algorithms, I: Traveling Salesman</h3><blockquote>
<ul>
<li>see commented slides</li>
<li>Approximation Guaranteee:<ul>
<li>alpha &gt;= 1</li>
<li><a href="http://7xklst.com1.z0.glb.clouddn.com/lec03_1.png" target="_blank" rel="external"></a></li>
</ul>
</li>
<li>TSP Approximation Algorithm<ul>
<li>Let cost(A) be the total length of the edges in some set A.</li>
<li>Let A* be the edges visited on the optimal tour.</li>
<li>Let A be the edges visited on the tour found by our algorithm.</li>
<li>Theorem. cost(A) =&lt; 2cost(A*).</li>
</ul>
</li>
<li>AA summary:<ul>
<li>A way to deal with hard problems</li>
<li>Analysis main idea: good lower bounds to &#x201C;approximate&#x201D; optimal</li>
<li>A constant -factor approximation algorithm for Metric Traveling Salesman uses MST</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="lec04-data-structures-for-minimum-spanning-trees-graphs-heaps"><a href="#lec04-Data-Structures-for-Minimum-Spanning-Trees-Graphs-amp-Heaps" class="headerlink" title="lec04 Data Structures for Minimum Spanning Trees: Graphs &amp; Heaps"></a>lec04 Data Structures for Minimum Spanning Trees: Graphs &amp; Heaps</h3><blockquote>
<ul>
<li>RAM: random access memory</li>
<li>ADT: Abstract data types</li>
<li>Priority Queue:<ul>
<li>also called a heap, holds items i that have keys key(i)</li>
</ul>
</li>
<li>heap FIFO tree:<ul>
<li>d: number of children, n: number of all the nodes</li>
<li>H: log n (height), h: current height(from bottom to top.)</li>
<li>insert takes O(logd_n),  because  height O(logd_n)(adding node as a leaf)</li>
<li>delete takes O(dlogd_n)(compare in every level)</li>
<li>makeheap takes O(n) time </li>
<li>findmin takes o(1) time </li>
<li><strong>Height</strong> counts from bottom</li>
<li><strong>Level</strong> counts from top</li>
<li>2^(H-h) nodes at height h</li>
</ul>
</li>
<li>heap sort:<ul>
<li>nlogn</li>
</ul>
</li>
<li>stack LIFO</li>
</ul>
</blockquote>
<h3 id="lec05-clustering-with-minimum-spanning-tree"><a href="#Lec05-Clustering-with-minimum-Spanning-Tree" class="headerlink" title="Lec05 Clustering with minimum Spanning Tree"></a>Lec05 Clustering with minimum Spanning Tree</h3><blockquote>
<ul>
<li>Clustering: an application of MST </li>
<li>Clustering: <ul>
<li>goal: Divide the n items up into k groups so that the minimum distance between items in different groups is maximized.<ul>
<li>Maximum minimum Distance:</li>
</ul>
<ul>
<li>idea:<ul>
<li>Maintain clusters as a set of connected components of a graph</li>
<li>Iteratively combine the clusters containing the two closest items by adding an edge between them</li>
<li>Stop when there are k clusters</li>
</ul>
</li>
<li>Another way to look at the algorithm<ul>
<li>C: delete the k-1 most expensive edgesfrom the MST.</li>
<li>any clustering c&#x2019; have same or smaller separation than C</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>It is exactly Kruskal&#x2019;s algorithm</li>
</ul>
</blockquote>
<h3 id="lec06-asymptotic-analysis"><a href="#Lec06-Asymptotic-Analysis" class="headerlink" title="Lec06 Asymptotic Analysis"></a>Lec06 Asymptotic Analysis</h3><blockquote>
<ul>
<li>Independent Set<ul>
<li>Definitation: Given a graph G = (V, E) an independent set is a set S \subsetq  V if no two nodes in S are joined by an edge.</li>
</ul>
</li>
<li>find the maximum Independent Set<ul>
<li>you can break the problem into:<ul>
<li>Search space: the set of feasible solutions</li>
<li>Objective function: a way of measuring how good the solution is</li>
</ul>
</li>
</ul>
</li>
<li>Efficient Algorithms:<ul>
<li>any algorithm is efficient if its <code>worst-case</code> runtime i bounded by a <code>polynomial</code> function of the input size.</li>
</ul>
</li>
<li>O(.): talks about the longest possible time an algorithm could take</li>
<li>ohm(.): talks about the shortest possible time.</li>
<li>theata: tight bound.  T(n) is theata(f(n)) if T(n) is O(f(n)) and ohm(f(n)).</li>
<li>sublinear time:<ul>
<li>we don&#x2019;t even look at every input.(binary search)</li>
</ul>
</li>
<li>Properties of O, Ohm, theata<ul>
<li>Transitivity of O<ul>
<li>f(n) = O(g(n)), g = O(h(n)) then f(n) = O(h(n))</li>
</ul>
</li>
<li>Multiplication<ul>
<li>if f (n) = O(f 0(n))                                                           \ and g(n) = O(g0(n)) then f (n)g(n) = O(f 0(n)g0(n)).</li>
</ul>
</li>
<li>Max</li>
</ul>
</li>
<li>some examples on proof of big O.<ul>
<li>take a look of the proof precedure &amp; hw2.</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="lec07-graph-traversals"><a href="#Lec07-Graph-Traversals" class="headerlink" title="Lec07 Graph Traversals"></a>Lec07 Graph Traversals</h3><blockquote>
<ul>
<li>Depth-First Search:<ul>
<li>result: a search tree(depth-first serach tree in unweighted, undirected graph)</li>
<li>One starts at the root and explores as far as possible along each branch before backtracking.</li>
<li>in general the DFS tree will be very different than the BFS tree <figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Pseudocode</span></div><div class="line"><span class="number">1</span>  procedure DFS-iterative(G,v):</div><div class="line"><span class="number">2</span>      let S be a <span class="built_in">stack</span></div><div class="line"><span class="number">3</span>      S.push(v)</div><div class="line"><span class="number">4</span>      <span class="keyword">while</span> S is not empty</div><div class="line"><span class="number">5</span>            v = S.pop()</div><div class="line"><span class="number">6</span>            <span class="keyword">if</span> v is not labeled as discovered:</div><div class="line"><span class="number">7</span>                label v as discovered</div><div class="line"><span class="number">8</span>                <span class="keyword">for</span> all edges from v to w in G.adjacentEdges(v) <span class="keyword">do</span></div><div class="line"><span class="number">9</span>                    S.push(w)</div><div class="line"><span class="comment">// recursive one</span></div><div class="line"><span class="number">1</span>  procedure DFS(G,v):</div><div class="line"><span class="number">2</span>      label v as discovered</div><div class="line"><span class="number">3</span>      <span class="keyword">for</span> all edges w in G.adjacentEdges(v) <span class="keyword">do</span></div><div class="line"><span class="number">4</span>          <span class="keyword">if</span> vertex w is not labeled as discovered then</div><div class="line"><span class="number">5</span>              recursively call DFS(G,w)</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</blockquote>
<pre><code>+ running time:  &#x398;(|V| + |E|)
</code></pre><blockquote>
<ul>
<li>Property of Non-DFS-Tree Edges   </li>
<li><p>Let x and y be nodes in the DFS tree TG such that{x,y} is an edge in undirected graph G. Then one of x or y is an ancestor of the other in TG .</p>
</li>
<li><p>Breadth-First Search:</p>
<ul>
<li>explore the nodes of a graph in increasing distance away from some starting vertex s</li>
<li><ul>
<li>running time:  &#x398;(|V| + |E|)</li>
</ul>
</li>
</ul>
</li>
<li><p>Property of Non-BFS-Tree Edges</p>
<ul>
<li>edge of G that do not appear in the tree connect nodes either in the same layer or adjacent layer. <figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">Breadth-First-Search(G, v):</div><div class="line"> <span class="number">2</span> </div><div class="line"> <span class="number">3</span>     <span class="keyword">for</span> each node n in G:            </div><div class="line"> <span class="number">4</span>         n.distance = INFINITY        </div><div class="line"> <span class="number">5</span>         n.parent = NIL</div><div class="line"> <span class="number">6</span> </div><div class="line"> <span class="number">7</span>     create empty <span class="built_in">queue</span> Q      </div><div class="line"> <span class="number">8</span> </div><div class="line"> <span class="number">9</span>     v.distance = <span class="number">0</span></div><div class="line"><span class="number">10</span>     Q.enqueue(v)                      </div><div class="line"><span class="number">11</span> </div><div class="line"><span class="number">12</span>     <span class="keyword">while</span> Q is not empty:        </div><div class="line"><span class="number">13</span>     </div><div class="line"><span class="number">14</span>         u = Q.dequeue()</div><div class="line"><span class="number">15</span>     </div><div class="line"><span class="number">16</span>         <span class="keyword">for</span> each node n that is adjacent to u:</div><div class="line"><span class="number">17</span>             <span class="keyword">if</span> n.distance == INFINITY:</div><div class="line"><span class="number">18</span>                 n.distance = u.distance + <span class="number">1</span></div><div class="line"><span class="number">19</span>                 n.parent = u</div><div class="line"><span class="number">20</span>                 Q.enqueue(n)</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>General Tree Growing</p>
<ol>
<li>let T be the current tree, and</li>
<li>Maintain a list of <code>frontier edges</code>: the set of edges of G that have one endpoint in T and one endpoint not in T:</li>
<li>Repeated choose a frontier edge(according to some law) and add it to T.</li>
</ol>
</li>
<li>Prim&#x2019;s ALgorithm: create a MST</li>
<li>DFS&#x2019;s next edge:<ul>
<li>select a frontier edge whose tree endpoint was discovered <strong>most recently</strong></li>
<li>use a <strong>stack</strong></li>
</ul>
</li>
<li>BFS&#x2019;s next edge:<ul>
<li>Select a frontier edge whose tree endpoint was discovered least recently</li>
<li>use a <strong>queue</strong></li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="lec08-applications-of-dfs-and-bfs"><a href="#Lec08-Applications-of-DFS-and-BFS" class="headerlink" title="Lec08 Applications of DFS and BFS"></a>Lec08 Applications of DFS and BFS</h3><blockquote>
<ul>
<li>bipartiteness<ul>
<li>if you can divide its nodes into 2 parts so that every edge goes between the two parts and not within a single part(&#x6240;&#x6709;&#x7684;&#x8FB9;&#x90FD;&#x94FE;&#x63A5;&#x4E00;&#x4E2A;&#x5DE6;&#x8FB9;&#x70B9;&#xFF0C;&#x4E00;&#x4E2A;&#x53F3;&#x8FB9;&#x70B9;)</li>
<li><a href="https://en.wikipedia.org/wiki/Bipartite_graph" target="_blank" rel="external">Bipartite</a> graphs can&#x2019;t contain odd cycles(the number of edge)</li>
<li>test bipartite:<ul>
<li>slide 5 (do a BFS, check whether any edge has both endpoints in hte same level)</li>
<li>two cases of bipartite:</li>
<li>no edge of G between two nodes of the same layer</li>
<li>z-x-y-z is a odd cycle.</li>
</ul>
</li>
</ul>
</li>
<li>DAGs:<ul>
<li><em>directed, acyclic graph</em> is a graph that contains no directed cycles.</li>
<li>useful when modeling project dependencies</li>
<li>Every DAG contains a vertex with no incoming edges</li>
</ul>
</li>
<li><p>Topological Sort:</p>
<ul>
<li>a topological sort (sometimes abbreviated toposort) or topological ordering of a directed graph is a linear ordering of its vertices such that for every directed edge uv from vertex u to vertex v, u comes before v in the ordering</li>
<li>runing time: O(\left|{V}\right| + \left|{E}\right|).O(|E|+|V|)</li>
<li><p>slide 11 Topological Sort Algorithm</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">pseudocode</div><div class="line">Topological sort:</div><div class="line"><span class="number">1.</span> Let i = <span class="number">1</span></div><div class="line"><span class="number">2.</span> Find a node u with no incoming edges, and let f (u) = i</div><div class="line"><span class="number">3.</span> Delete u from the graph</div><div class="line"><span class="number">4.</span> Increment i</div><div class="line">Implementation: Maintain</div><div class="line">I Income[w] = number of incoming edges <span class="keyword">for</span> node w</div><div class="line">I a <span class="built_in">list</span> S of nodes that currently have no incoming edges.</div><div class="line"><span class="comment">// from wikipedia</span></div><div class="line">L &#x2190; Empty <span class="built_in">list</span> that will contain the sorted elements</div><div class="line">S &#x2190; Set of all nodes with no incoming edges</div><div class="line"><span class="keyword">while</span> S is non-empty <span class="keyword">do</span></div><div class="line">    remove a node n from S</div><div class="line">    add n to tail of L</div><div class="line">    <span class="keyword">for</span> each node m with an edge e from n to m <span class="keyword">do</span></div><div class="line">        remove edge e from the graph</div><div class="line">        <span class="keyword">if</span> m has no other incoming edges then</div><div class="line">            insert m into S</div><div class="line"><span class="keyword">if</span> graph has edges then</div><div class="line">    <span class="keyword">return</span> error (graph has at least one cycle)</div><div class="line"><span class="keyword">else</span> </div><div class="line">    <span class="keyword">return</span> L (a topologically sorted order)</div></pre></td></tr></table></figure>
</li>
<li><p>Any DAG has at least one topological ordering, and algorithms are known for constructing a topological ordering of any DAG in linear time.</p>
</li>
</ul>
</li>
<li>Let (U,V) be an edge of a DAG D. What can we say about the relation between f[u] and f[v]?<ul>
<li>discovery time: d[u] = the time at which u is first visited</li>
<li>finishing time: f[u] = the time at which all u and all its<ul>
<li>d[u] &lt;= f[u]<br>neighbors have been visited.</li>
</ul>
</li>
<li>f[v] &lt; f[u] if (u,v) \in D</li>
</ul>
</li>
<li>another Topological Sort Algoritm <ul>
<li>Every edge(u,v) in a DAG has f[v] &lt; f[u]</li>
<li>if we list nodes from largest f[u] to smallest f[u] then every edge goes from left to right.</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="lec09-applications-of-shortest-paths-and-a"><a href="#Lec09-Applications-of-Shortest-paths-and-A" class="headerlink" title="Lec09 Applications of Shortest paths and A*"></a>Lec09 Applications of Shortest paths and A*</h3><blockquote>
<ul>
<li>Dijkstra&#x2019;s algorithm:<ul>
<li>finding the shortest paths between nodes in a graph</li>
<li>It picks the unvisited vertex with the lowest-distance, calculates the distance through it to each unvisited neighbor, and updates the neighbor&#x2019;s distance if smaller. Mark visited (set to red) when done with neighbors.</li>
<li>run time (O|E| + |V|log|V|)</li>
<li>assumes it knows nothing about nodes it hasn&#x2019;t reached during the algorithm </li>
</ul>
</li>
<li>A* algorithm:<ul>
<li>g(u) = best distance from s to u found so far.</li>
<li>f(u) = g(u) + h(u) = estimate of the length of the best path<br>from s to t through u.</li>
</ul>
</li>
<li><p>Choice of h(u), the heuristic distance:</p>
<ul>
<li>let h<em>(u) be the real shortest distance form u to t. A heuristic h(u) is </em>admissible<em> if h(u) &lt;= h</em>(u) for all u // heuristic smaller than optimal<ul>
<li>guessed distance is less than the real distance</li>
</ul>
</li>
<li>when h(u) = 0 for all u: A* = Dijkstra&#x2019;s algorithm</li>
<li>if h(u) is admissible, then A* is guaranteed to find an optimal route to the destination t.<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">//pseudocode</div><div class="line">1: g[s]   0</div><div class="line">2: f[s]   g[s] + h[s]</div><div class="line">3: Heap   MakeHeap((s,f[s])) # heap key is f[s]</div><div class="line">4: repeat</div><div class="line">5: u   DeleteMin(Heap) # Expand node with minimum f[u]</div><div class="line">6: if u = goal then return</div><div class="line">7: for v 2 Neighbors(u) do</div><div class="line">8: if g[u] + d(u,v) &lt; g[v] then</div><div class="line">9: parent[v]   u</div><div class="line">10: g[v]   g[u] + d(u,v)</div><div class="line">11: f[v]   g[v] + h(v)</div><div class="line">12: if v 62 Heap then</div><div class="line">13: Insert(Heap, v, f[v])</div><div class="line">14: else</div><div class="line">15: ReduceKey(Heap, v, f[v]) # Sift up for new key</div><div class="line">16: until Heap is empty</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>BFS:</p>
<ul>
<li>running time: O(|V| + |E|)</li>
<li>application: edge weights all the same</li>
</ul>
</li>
<li>Dijkstra:<ul>
<li>running time: O(|E|log|V|)</li>
<li>application: positive edge weights</li>
</ul>
</li>
<li>Astar:<ul>
<li>running time: O(possibly large)</li>
<li>application: have heuristic h(u)</li>
</ul>
</li>
<li>Bellman -Ford:<ul>
<li>running time: O(|E|*|V|)</li>
<li>application: arbitrary edge weights</li>
</ul>
</li>
<li>Algorithmic design techniques:<ul>
<li>Based on BFS or DFS (bipartite testing, topological sort)</li>
<li>Greedy tree growing (Prim&#x2019;s, Dijkstra&#x2019;s)</li>
<li>A* (design an admissible heuristic: TSP)</li>
</ul>
</li>
<li>a good admissible:<ul>
<li>0</li>
<li>length of the smallest unused edge leaving last node </li>
<li>length of the MST on all nodes except those used ones.</li>
<li>length of the minimum spanning tree on all nodes except<br>a2, &#x2026;a k-1 path from ak to a1 is a MST, so MST must<br>be of less cost than the TSP completion.</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="lec10-shortest-paths-in-a-graph"><a href="#Lec10-Shortest-Paths-in-a-Graph" class="headerlink" title="Lec10 Shortest Paths in a Graph"></a>Lec10 Shortest Paths in a Graph</h3><blockquote>
<ul>
<li>Goal: find the shortest path from a given node s to every other node in the graph(Directed weighted graph)</li>
<li>Prim&#x2019;s algorithm: find MST</li>
<li>Dijkstra&#x2019;s algorithm: Shortest Paths<ul>
<li>maintain a list of <em>frontier edges</em></li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="lec11-minimum-spanning-arborescences"><a href="#Lec11-Minimum-Spanning-Arborescences" class="headerlink" title="Lec11 Minimum Spanning Arborescences"></a>Lec11 Minimum Spanning Arborescences</h3><blockquote>
<ul>
<li>minimum cost arborescene[,&#x251;rb&#x259;&#x2019;r&#x25B;sns] MCA<ul>
<li>an arborescene of G(directed graph) rooted at r is a subgraph of G with no cycles such that there is a path from r to every other vertex of r.</li>
<li>the idea of creating super node </li>
</ul>
</li>
<li>find algorithm for MCA<ul>
<li><ol>
<li>Transform G into G&#x2019; by subtracting the smallest incoming edge weight for each node u!=r</li>
</ol>
</li>
<li><ol>
<li>Choose T by selecting an arbitrary 0-weight edge that enters<br>each node u != r</li>
</ol>
</li>
<li><ol>
<li>If T has no cycles, return it as the optimal.</li>
</ol>
</li>
<li><ol>
<li>Otherwise,find a cycle C and collapse it to a super node C0<br>get a new graph G&#x2019;&#x2019;</li>
</ol>
</li>
<li><ol>
<li>Find the MCA T&#x2019; on G&#x2019;&#x2019; (recursively).</li>
</ol>
</li>
<li><ol>
<li>Expand C&#x2019; back into a cycle, adding all edges of C except the<br>last to T&#x2019;.</li>
</ol>
</li>
<li>return T&#x2019;</li>
</ul>
</li>
<li>use induction to prove the correstness of the find algorithm</li>
<li>running time O(|V||E|)<ul>
<li>create 0 weight O(|E|)</li>
<li>in each recursive step, shrink the graph by at least 1 node O(|V|)</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="lec12-shortest-paths-with-negative-weights"><a href="#Lec12-Shortest-paths-with-Negative-Weights" class="headerlink" title="Lec12 Shortest paths with Negative Weights"></a>Lec12 Shortest paths with Negative Weights</h3><blockquote>
<ul>
<li>problem: Given directed graph G with weighted edges d(u,v) that may be positive or negative, find the shorest path from s to t.(&#x4E00;&#x70B9;&#x53BB;&#x53E6;&#x4E00;&#x70B9;)<ul>
<li>you can not add a large weight(the number of edges matters)</li>
</ul>
</li>
<li><p><a href="https://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm" target="_blank" rel="external">Bellman-Ford:</a></p>
<ul>
<li><p>after applying the ford step until dist(u)+d(u,v) &gt; dist(v) for all edges, dist(u) will equal the shortest - path distance from s to u for all u.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">ShortestPath(G, s, t):</div><div class="line">    Initialize dist[u] = <span class="number">1</span> <span class="keyword">for</span> all u</div><div class="line">    dist[s] = <span class="number">0</span></div><div class="line">    # <span class="built_in">queue</span> tracks nodes that are candidates <span class="keyword">for</span> Ford rule</div><div class="line">    <span class="built_in">queue</span> = [s]</div><div class="line">    <span class="keyword">while</span> <span class="built_in">queue</span> is not empty:</div><div class="line">        v = front of <span class="built_in">queue</span> (and remove v)</div><div class="line">        <span class="keyword">for</span> u <span class="number">2</span> neighbors(v):</div><div class="line">            # Apply Ford rule <span class="keyword">if</span> we can</div><div class="line">            <span class="keyword">if</span> dist[v] + d(v,u) &lt; dist[u]:</div><div class="line">                dist[u] = dist[v] + d(v,u)</div><div class="line">                parent[u] = v</div><div class="line">                <span class="keyword">if</span> u <span class="number">62</span> <span class="built_in">queue</span>: put w at end of <span class="built_in">queue</span></div></pre></td></tr></table></figure>
</li>
<li><p>running time: O(mn)</p>
</li>
<li>normally slower than 32&#x2019;s algorithm</li>
</ul>
</li>
<li>difference between Bellman Ford and Dijkstra&#x2019;s algorithm<ul>
<li>negative VS non-negative:<ul>
<li>Bellman-Ford algorithm is a single-source shortest path algorithm, which allows for negative edge weight and can detect negative cycles in a graph.</li>
<li>Dijkstra algorithm is also another single-source shortest path algorithm. However, the weight of all the edges must be non-negative.</li>
</ul>
</li>
<li>time complexity<ul>
<li>Dijkstra&#x2019;s algorithm: <code>Theta((|E|+|V|)log|V|)</code></li>
<li>Bellman&amp;Ford algorithm <code>O(|V||E|)</code></li>
</ul>
</li>
<li>vertexes:<ul>
<li>The vertexes in Dijkstra&#x2019;s algorithm contain the whole information of a network. There is no such thing that every vertex only cares about itself and its neighbors. On the other hand, Bellman-Ford algorithm&#x2019;s nodescontain only the information that are related to. This information allows that node just to know about which neighbor nodes can it connect and the node that the relation come from, mutually. Dijkstra&#x2019;s algorithm is faster than Bellman-Ford&#x2019;s algorithm however the second algorithm can be more useful to solve some problems, such as negative weights of paths.</li>
</ul>
</li>
<li>greedy:<ul>
<li>Dijkstra&#x2019;s algorithm greedily selects the minimum-weight node that has not yet been processed, and performs this relaxation process on all of its outgoing edges; by contrast, the Bellman&#x2013;Ford algorithm simply relaxes all the edges, and does this |V|-1 times</li>
</ul>
</li>
</ul>
</li>
<li>prove of their exist a path and it&#x2019;s the shorest path:<ul>
<li>using mathematical induction<ul>
<li>base case &amp; induction hypothesis &amp; induction step </li>
</ul>
</li>
</ul>
</li>
<li>which edges are candiates for the ford rule<ul>
<li>Whenever we change dists (u) we add u to a queue.</li>
<li>To look for an edge to apply the Ford rule to we take a node<br>of the queue and look at all its edges.</li>
</ul>
</li>
<li>A dynamic programming view of Bellman-Ford<ul>
<li>recurrence</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="lec13-skip-lists"><a href="#Lec13-Skip-Lists" class="headerlink" title="Lec13 Skip Lists"></a>Lec13 Skip Lists</h3><blockquote>
<ul>
<li>General List (abstract data type)<ul>
<li>linked list:<ul>
<li>benefits:<ul>
<li>eazy to insert&amp;delete in O(1) time</li>
<li>don&#x2019;t need to estimate total memory needed</li>
</ul>
</li>
<li>Drawbacks:<ul>
<li>Hard to search in less than O(n) time ,M</li>
<li>Hard to jump to the middle</li>
</ul>
</li>
</ul>
</li>
<li>Skip lists<ul>
<li>fix these drawbacks</li>
<li>good data structure for a dictionary ADT</li>
</ul>
</li>
</ul>
</li>
<li>Perfect Skip Lists<ul>
<li>keys in sorted order </li>
<li>O(log n) levels</li>
<li>each higher level contains 1/2 the elements ofthe level below it</li>
<li>header &amp; sentinel nodes are in every level </li>
<li>nodes contain between 1 and O(logn) pointers</li>
<li>search time:<ul>
<li>O(log n) levels </li>
<li>will visit at most 2 nodes per level </li>
</ul>
</li>
<li>insert &amp; Delete <ul>
<li>too structured to support efficient updates </li>
<li>instead: design structure so that we expect 1/2 the items to be carried up to the next level </li>
</ul>
</li>
<li>solution: randomization:<ul>
<li>each node is promoted to the next higher level with probability 1/2 </li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="lecture-14-splay-trees"><a href="#Lecture-14-Splay-Trees" class="headerlink" title="Lecture 14 Splay Trees"></a>Lecture 14 Splay Trees</h1><blockquote>
<ul>
<li>Binary search Trees<ul>
<li>if a node has key <strong>k</strong>, then all the keys in the left subtree are &lt; k.<br>right side vice versa</li>
<li>find: walk left or right according to key comparision</li>
<li>insert: put the new node where a find for it would have fallen off the tree </li>
<li>Delete: u (value to delete)<ul>
<li>at leaf: just delete it:</li>
<li>have 1 child: move that child up to be a child of u&#x2019;s parent </li>
<li>have 2 children: find the smallest key in the right subtree, delete it, and replace u with that key</li>
</ul>
</li>
</ul>
</li>
<li>splay Trees(a balanced tree)<ul>
<li>no extra storage needed </li>
<li>amortized performance</li>
<li>rotation &amp; double rotation</li>
</ul>
</li>
<li>3 cases for splay operation<ul>
<li>case 1: no grandparent<ul>
<li>slide 24</li>
</ul>
</li>
<li>case 2: zigzag(right,left) the direction you go:<ul>
<li>slide 25 x <p(x)>p2(x) -&gt;  p2(x) &lt; x &lt; p(x)</p(x)></li>
</ul>
</li>
<li>case 3: zigzig(left,left) the direction you go:<ul>
<li>slide 25 x <p(x) <="" p2(x)="" -=""> x &lt;p(x) &lt;p2(x)</p(x)></li>
</ul>
</li>
</ul>
</li>
<li>Splay idea <ul>
<li>The find/insert/delete operations can be written in terms<br>of the &#x201C;splay&#x201D; operation.</li>
<li>Splay is implemented by doing a standard BST &#x201C;find&#x201D;<br>and then applying particular rotations walking back up<br>toward the root.</li>
<li>This is somewhat like the idea of &#x201C;path compression&#x201D; for<br>the tree-based union-find data structure: during a find,<br>you flatten out the tree.</li>
<li>it costs at most 3[logn] + 1 new dollars to splay, keeping the money invariant</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="lecture-15-b-trees"><a href="#lecture-15-B-Trees" class="headerlink" title="lecture 15 B-Trees"></a>lecture 15 B-Trees</h1><blockquote>
<ul>
<li>when we have overflow:<ul>
<li>we check the neighbors first, try to do <strong>key rotation</strong> slide 16</li>
<li>if both siblings are filled, you have to split the node <ul>
<li>slide 24: [22 25 27] -&gt; [22] [27], 25 move up </li>
<li>so when you have three number in the same node, splid and  move the middle one up.</li>
</ul>
</li>
</ul>
</li>
<li>A B-tree of order b is an a,b-tree with b &gt;= 2a - 1 (we need enough children to make split work) a &gt;= 2<ul>
<li>in other words,we choose the largest allowed a.</li>
</ul>
</li>
<li>allowable operation: key rotation; split; merge </li>
<li>B-tree:<ul>
<li>is an a,b-tree with b = 2a - 1, choose the largest allowed a </li>
<li>want to have large b if bringing a node into memory is slow </li>
<li>EX. a B-tree of order 1023, then a is 512</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="lecture-16-suffix-trees"><a href="#lecture-16-Suffix-trees" class="headerlink" title="lecture 16 Suffix trees"></a>lecture 16 Suffix trees</h1><blockquote>
<ul>
<li>Given a suffix trie(pronounced as try) T and a string q, how can we:<ul>
<li>determine whether q is a substring of T <ul>
<li>follow the path for q starting from the root O(|query|)</li>
</ul>
</li>
<li>check whether q is a suffix of T <ul>
<li>follow the path for q starting from the root, if you end at a leaf at the end of q, then q is a suffix of T </li>
</ul>
</li>
<li>count how many times q appear in T<ul>
<li>follow the path for q starting from the root, the number of leaves under the node you end up in is the number of occurences of q. </li>
</ul>
</li>
<li>find the longest repeat in T <ul>
<li>find the deepest node that has at least 2 leaves under it.</li>
</ul>
</li>
<li>find the longest common substring of T and q<ul>
<li>use suffix tries (mnhII) </li>
</ul>
</li>
</ul>
</li>
<li>After we&#x2019;ve built the suffix trees, queries can be answerd in <strong>O(|query|)</strong></li>
<li>Space-Efficient Suffix Trees(linear space) P35</li>
<li>Storing more than one string with <strong>Generalized Suffix Trees</strong><ul>
<li>Ukkonen&#x2019;s algorithm</li>
<li>longest common substring of S and T:<ul>
<li>Build generalized suffix tree for {S, T},Find the deepest node that has has descendants from both strings (containing both #1 and #2)</li>
</ul>
</li>
<li>Determine the strings in a database {S1, S2, S3, &#x2026;, Sm} that contain<br>query string q:<ul>
<li>Build generalized suffix tree for {S1, S2, S3, &#x2026;, Sm}<br>Follow the path for q in the suffix tree.<br>Suppose you end at node u: traverse the tree below u, and<br>output i if you find a string containing #i.</li>
</ul>
</li>
</ul>
<ul>
<li>Longest common Extension(LCE)<ul>
<li>use <strong>longest common extension</strong>(LCA) to solve it.  P45 </li>
</ul>
</li>
<li>Using LCE to Find <strong>Palindromes</strong></li>
<li>K-mismatch using LCE</li>
<li>Recap:<ul>
<li>suffix tries natural way to store a string &#x2013; serach, count occurrences, and many other queries answerable easily</li>
<li>but they are not space efficient: O(n^2) space</li>
<li>suffix trees are space optmial: O(n), but require a little more subtle algorithm to construct</li>
<li>suffix trees acan be constructed in O(n) time using Ukkonen&#x2019;s algorithm </li>
<li>similar ideas can be used to store sets of strings</li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="lecture-17-dynamic-programming-subset-sum-knapsack"><a href="#lecture-17-Dynamic-Programming-Subset-Sum-amp-Knapsack" class="headerlink" title="lecture 17 Dynamic Programming: Subset Sum &amp; Knapsack"></a>lecture 17 Dynamic Programming: Subset Sum &amp; Knapsack</h1><blockquote>
<ul>
<li>generally applies to algorithms where the <strong>brute force algorithm would be exponential</strong></li>
<li>problem: <code>subset sum</code><ul>
<li>maximize weight P 3</li>
<li>constraint on the weight sum </li>
<li>opt-&gt; value we have.</li>
</ul>
</li>
<li>filling in the Matrix<ul>
<li>fill matrix from bottom to top, left to right </li>
<li>take the turning point as the values we use </li>
<li>O(nw)- pseudopolynomial </li>
</ul>
</li>
<li>problem: <code>subset sum</code><ul>
<li>maximize the value P 19</li>
<li>P 24 comparision with <code>subset sum</code></li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="lecture-18-more-dynamic-programming-examples"><a href="#lecture-18-More-Dynamic-Programming-Examples" class="headerlink" title="lecture 18 More Dynamic Programming Examples"></a>lecture 18 More Dynamic Programming Examples</h1><blockquote>
<ul>
<li>segmented Least Squares<ul>
<li>C*K + sigma_fit(Si) P 4</li>
</ul>
</li>
<li>matrix-chain multiplication<br> A1(a by b) <em> A2 (b by c) -&gt; number of operation: a</em>b*b</li>
<li>Optimal Binary Search Trees</li>
</ul>
</blockquote>
<h1 id="lecture-19-string-comparison"><a href="#lecture-19-String-Comparison" class="headerlink" title="lecture 19 String Comparison"></a>lecture 19 String Comparison</h1><blockquote>
<ul>
<li>gap:<ul>
<li>the cost of inserting a &#x201C;-&#x201C; character, representing an <code>insertion</code> or <code>deletion</code></li>
</ul>
</li>
<li>cost(x,y):<ul>
<li>is the cost of aligning character x with character y. In the simplest case, cost(x,x) = 0 and cost(x,y) = mismatch penalty.</li>
</ul>
</li>
<li>Goal: <ul>
<li>compute the edit distance by finding the <strong>lowest cost alignment</strong></li>
<li>cost of an alignment is:<ul>
<li>sum of the cost (x,y) for the pairs of characters that are aligned <ul>
<li>gap*number of &#x201C;-&#x201C; characters inserted</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Requirements for DP to apply:<ul>
<li>Optimal value of the original problem can be computed from some<br>similar subproblems</li>
<li>There are only a polynomial # of subproblems</li>
<li>There is a &#x201C;natural&#x201D; ordering of subproblems, so that you can solve a<br>subproblem by only looking at smaller subproblems.</li>
</ul>
</li>
<li>Dynamic programming Design Strategy<ul>
<li><ol>
<li>Write definitions for subproblems that generalize the problem you are trying to solve in some way</li>
</ol>
<ul>
<li>Only worry about computing the value of the optimal solution.</li>
<li>Don&#x2019;t worry too much in this step about how you would solve the subproblem.</li>
<li>Hint for choosing subproblems: what is the last decision that would be made when<br>writing down the optimal solution?</li>
</ul>
</li>
<li><ol>
<li>Write the solution to every subproblem in terms of the solutions to<br>smaller problems.</li>
</ol>
<ul>
<li><ol>
<li>Give an ordering to solve the subproblems so that when trying to solve a<br>subproblem, you have already solved the subproblems it depends on.</li>
</ol>
</li>
<li><ol>
<li>Show that there are are only a polynomial number of subproblems and<br>that solving each takes a small amount of time.</li>
</ol>
</li>
<li><ol>
<li>Describe how following traceback arrows will give the actual solution.</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li>recursive solution - P 19</li>
</ul>
</blockquote>
<h1 id="lecture-20-rna-folding"><a href="#lecture-20-RNA-Folding" class="headerlink" title="lecture 20 RNA Folding"></a>lecture 20 RNA Folding</h1><blockquote>
<ul>
<li>OPT(i, j) = max {OPT(i, j -1) # no connecting<pre><code>{maxt{1 + OPT(i, t -1) + OPT(t+1,j-1)
</code></pre></li>
<li>In order of increasing j - i </li>
<li>running time:<ul>
<li>O(n2) subproblems</li>
<li>Each takes O(n) time to solve(have to search over all possible choices of t)</li>
<li>Total running time is O(n3).</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="lecture-21-network-flows"><a href="#lecture-21-Network-Flows" class="headerlink" title="lecture 21 Network Flows"></a>lecture 21 Network Flows</h1><blockquote>
<ul>
<li>maximum Flow problem.</li>
<li>residual graph <ul>
<li>forward edges </li>
<li>backward edges </li>
</ul>
</li>
<li>augmenting paths<ul>
<li>used to update graph </li>
</ul>
</li>
<li><strong>Ford-Fulkerson</strong> Algorithm <ul>
<li>computes the maximum flow in a flow network</li>
<li>running time pseudo-polynomial</li>
</ul>
</li>
<li>Proof of correctness<ul>
<li>the minimum capacity cut constrains the maximum flow the most.(<strong>in fact always equal</strong>)</li>
</ul>
</li>
<li>Summary:<ul>
<li>Ford-Fulkerson algorithm can find max flow in O(mC) time.<ul>
<li><em>m</em> is number of edges, C is the capacity for each edge </li>
</ul>
</li>
<li>Algorithm idea: Send flow along some path with capacityleft, possibly &#x201C;erasing&#x201D; some flow we&#x2019;ve already sent. Use residual graph to keep track of remaining capacities and owwe&#x2019;ve already sent.</li>
<li>We can eliminate C to get a true polynomial algorithm by<br>using BFS to find our augmenting paths.</li>
<li>All cuts have capacity &gt;= the value of all<br>ows.</li>
<li>Know the flow is maximum because its value equals the capacity of some cut.</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="lecture-21-maximum-bipartite-matching"><a href="#lecture-21-Maximum-Bipartite-Matching" class="headerlink" title="lecture 21 Maximum Bipartite Matching"></a>lecture 21 Maximum Bipartite Matching</h1><blockquote>
<ul>
<li>same as network flow but without flows or even networks</li>
<li>Maximum Bipartite Matching:<ul>
<li>maximize the number of edges </li>
<li>solution:<ul>
<li>reduce bipartite matching to net flow </li>
<li>running time O(mn)</li>
</ul>
</li>
</ul>
</li>
<li>summary: Bipartite matching<ul>
<li>Fold-Fulkerson can find a maximum matching in a bipartite graph in O(mn) time.</li>
<li>Fold-Fulkerson can find a maximum matching in a bipartite graph in O(mn)<br>time.</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="lecture-22-image-segmentation"><a href="#lecture-22-image-Segmentation" class="headerlink" title="lecture 22 image Segmentation"></a>lecture 22 image Segmentation</h1><blockquote>
<ul>
<li></li>
</ul>
</blockquote>
<h1 id="lecture-23-max-flow-extensions"><a href="#lecture-23-Max-flow-extensions" class="headerlink" title="lecture 23 Max-flow extensions"></a>lecture 23 Max-flow extensions</h1><blockquote>
<ul>
<li>circulations with demands<ul>
<li>represent supply as negative demand  </li>
</ul>
</li>
<li>lower bounds on some edges<ul>
<li><ol>
<li>subtract LB from the capacity of each edge e,</li>
</ol>
</li>
<li><ol>
<li>subtract Lv from the demand of each node v </li>
</ol>
</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="lecture-24-linear-programming"><a href="#lecture-24-linear-programming" class="headerlink" title="lecture 24 linear programming"></a>lecture 24 linear programming</h1><blockquote>
<ul>
<li>we have:<ul>
<li>A matrix with m rows and n columns</li>
<li>b vector of length m </li>
<li>c vector of length n</li>
</ul>
</li>
<li>so:<ul>
<li>maximize cx, w.r.t ax &lt;b </li>
</ul>
</li>
<li>Solving method<ul>
<li>Simplex Method:<ul>
<li>not a <strong>polynomial time algorithm</strong> but fast </li>
</ul>
</li>
<li>Ellipsoid Method<ul>
<li>though <strong>polynomial time</strong>, but horribly slow in practise</li>
</ul>
</li>
<li>Interior Point Method<ul>
<li>polynomial &amp; practical</li>
</ul>
</li>
</ul>
</li>
<li>can solve problem as:<ul>
<li>maximum flow P12</li>
<li>minimum cost flow P18</li>
<li>shortest path P22</li>
</ul>
</li>
<li>Integer Linear Programming <ul>
<li>NP-hard problem </li>
<li>Minimum Vertex Cover</li>
<li>Vertex Cover as an ILP</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="lecture-25-the-simplex-algorithm"><a href="#lecture-25-The-simplex-Algorithm" class="headerlink" title="lecture 25 The simplex Algorithm"></a>lecture 25 The simplex Algorithm</h1><blockquote>
<ul>
<li><ol>
<li>write LP with slack variables </li>
</ol>
</li>
<li><ol>
<li>Choose a variable in the objective with a positive coefficient to increaser</li>
</ol>
</li>
<li><ol>
<li>Among the equations where v has a negative coefficient qiv, choose the strictest one </li>
</ol>
</li>
<li><ol>
<li>rewrite the strictest equation to put v on the left side, and substitiute for v everywhere else </li>
</ol>
</li>
<li><ol>
<li>if all the coefficients are smaller than 0, we are done; otherwise, jump back to step 2 </li>
</ol>
</li>
</ul>
</blockquote>
<h1 id="lecture-26-the-classes-p-and-np"><a href="#lecture-26-The-classes-P-and-NP" class="headerlink" title="lecture 26 The classes P and NP"></a>lecture 26 The classes P and NP</h1><blockquote>
<ul>
<li>NP-hard:<ul>
<li>no polynomial algorithm exists to solve this problem </li>
</ul>
</li>
<li>Decision problem <ul>
<li>just ask for a <code>yes</code> or a <code>no</code> </li>
<li>Decision is no harder than Optimization</li>
</ul>
</li>
<li>The class P: set of problems that can be decided in polynomial number of steps.</li>
<li>The class NP: is the set of problems for which evidence of a YES instance can be checked in polynomial time if some one gives you a solution <ul>
<li>the set of languages for which there exists an efficient certifier.</li>
</ul>
</li>
<li><strong>P belongs to NP</strong></li>
</ul>
</blockquote>
<h1 id="lecture-27-reductions-np-completeness"><a href="#lecture-27-Reductions-amp-NP-completeness" class="headerlink" title="lecture 27 Reductions &amp; NP-completeness"></a>lecture 27 Reductions &amp; NP-completeness</h1><blockquote>
<ul>
<li>reductions as tool for hardness <ul>
<li>if you had a black box that can solve instances of problem X, how can you solve any instance of Y using polynomial number of steps, plus a polynomial number of calls to the balck box that solves X?</li>
</ul>
</li>
<li>We reduce to the problem we want to show is the harder problem. P5</li>
<li>NP-completeness <ul>
<li>if <strong>x</strong> IS NP-complete<ul>
<li>X belongs to NP (proof step1)</li>
<li>for all Y belongs to NP, Y is <code>polynomial time</code> reduciable to X.(proof step2)</li>
<li>x is at least as hard as every problem in NP.</li>
</ul>
</li>
</ul>
</li>
<li>Cook-Levin theorem<ul>
<li>used to find the first NP-complete problem </li>
</ul>
</li>
<li>we know the following problem as NP-complete<ul>
<li>Vertex Cover<ul>
<li>a vertex cover of a graph is a set S of nodes such that every edge has at least one endpoint in S </li>
</ul>
</li>
<li>Independent Set <ul>
<li>a set s of vertices is independent in G if there are no edges between any vertices in S.</li>
</ul>
</li>
<li>Set Cover<ul>
<li>given a set U of elements and a collection S1,&#x2026;,Sm of subsets of U, is there a collection of at most k of these sets whose union equals U. </li>
</ul>
</li>
</ul>
</li>
<li><code>Warning</code>: reduce the known NP-complete problem to the problem you are interested in </li>
</ul>
</blockquote>
<h1 id="lecture-28-satcoloring-hamiltonian-cycle-tsp"><a href="#lecture-28-SAT-Coloring-Hamiltonian-Cycle-TSP" class="headerlink" title="lecture 28 SAT,Coloring, Hamiltonian Cycle, TSP"></a>lecture 28 SAT,Coloring, Hamiltonian Cycle, TSP</h1><blockquote>
<ul>
<li>P2  reductions graph: very importmant</li>
<li>P3 boolean formulas<ul>
<li>variables x1,x2,x3</li>
<li>terms     t1,t2,t3</li>
<li>clauses   t1 V t2 V&#x2026; Vl</li>
</ul>
</li>
<li>satisfiying assignment - make every clause true</li>
<li>SAT <ul>
<li>given a set of clauses C1,&#x2026;,Ck over variables X = {X1,&#x2026;,Xn} is there a satisfying assignment?</li>
</ul>
</li>
<li>3SAT<ul>
<li>given a set of clauses C1,&#x2026;,Ck, each of length 3, over variables X = {X1,&#x2026;,Xn} is there a satisfying assignment?</li>
</ul>
</li>
<li>Cook-Levin theorem<ul>
<li>SAT is NP-complete</li>
<li>a computer is just a circuit, and SAT encodes a kind circuit </li>
</ul>
</li>
<li>SAT &lt;=P 3SAT &lt;=P Independent Set</li>
<li>Hamiltonian Cycle Problem <ul>
<li>Given a directed graph G, is there a cycle that visits every vertex exactly once? </li>
<li>NP complete P16</li>
</ul>
</li>
<li>Hamiltonian path Problem <ul>
<li>Given a directed graph G, is there a  that visits every vertex exactly once? </li>
</ul>
</li>
<li>1st step: prove it&#x2019;s np</li>
<li>2nd step: prove reduce to </li>
</ul>
</blockquote>
<h1 id="lecture-29-np-completeness-of-3-dimensional-matching-and-subset-sum"><a href="#lecture-29-NP-completeness-of-3-Dimensional-Matching-and-Subset-Sum" class="headerlink" title="lecture 29 NP-completeness of 3 Dimensional Matching and Subset Sum"></a>lecture 29 NP-completeness of 3 Dimensional Matching and Subset Sum</h1><h1 id="lecture-30-randomized-mincut"><a href="#lecture-30-Randomized-Mincut" class="headerlink" title="lecture 30 Randomized Mincut"></a>lecture 30 Randomized Mincut</h1><blockquote>
<ul>
<li>allow our algorithms to flip some random coins to make their choices </li>
<li>often run innnn expectation faster than deterministic algorithms</li>
<li><p>Contraction Algorithm  </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span> G contains more than <span class="number">2</span> nodes</div><div class="line">  choose an edge e uniformly at random</div><div class="line">  contract e, replacing its endpoints with a <span class="keyword">new</span> node w</div></pre></td></tr></table></figure>
<ul>
<li>a polynomial algorithm</li>
</ul>
</li>
<li>BPP<ul>
<li>the class of decision problems L for which there is an polynomial-time, randomized algorithm A with 2 properties.<ul>
<li>YES possibility &gt;= 2/3</li>
<li>NO possibility &lt;= 1/3 </li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="lecture-31-approximation-algorithms"><a href="#lecture-31-approximation-algorithms" class="headerlink" title="lecture 31 approximation algorithms"></a>lecture 31 approximation algorithms</h1><blockquote>
<ul>
<li>one way to solve NP-complete problems<ul>
<li>heuristics </li>
</ul>
</li>
<li>split the solution into two parts:<ul>
<li>the contribution of the last item on M </li>
<li>the rest of load on M <h1 id="final-examination-preparation"><a href="#final-examination-preparation" class="headerlink" title="final examination preparation"></a>final examination preparation</h1></li>
</ul>
</li>
<li>slides + homework </li>
<li>Monday<ul>
<li>try to review as many slides as you can </li>
</ul>
</li>
<li>Tuesday</li>
<li>Wednesday</li>
<li>Algorithm Design Techniques<ul>
<li>Greedy</li>
<li>Tree-growing</li>
<li>A*</li>
<li>Dynamic Programming</li>
<li>Network Flow </li>
<li>Linear and integer Programming </li>
<li>Reductions(and NP-completeness)</li>
<li>Randomized algorithms </li>
<li>Approximation algorithms</li>
</ul>
</li>
<li>Data Structures<ul>
<li>heaps </li>
<li>Union Find </li>
<li>Graphs</li>
<li>Binary Search Trees </li>
<li>Splay trees</li>
<li>Suffix Trees </li>
<li>B-tree</li>
<li>Skip Lists </li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="other-stuff-learned-by-myself"><a href="#other-stuff-learned-by-myself" class="headerlink" title="other stuff learned by myself"></a>other stuff learned by myself</h1><h2 id="red-black-tree-map-in-c"><a href="#Red-black-tree-amp-map-in-C" class="headerlink" title="Red black tree &amp; map in C++"></a>Red black tree &amp; map in C++</h2><p><a href="https://www.youtube.com/watch?v=O3hI9FdxFOM" target="_blank" rel="external">https://www.youtube.com/watch?v=O3hI9FdxFOM</a></p>
<blockquote>
<ul>
<li>Balanced search trees ( tree of height O(logn) )<ul>
<li>AVL tree</li>
<li>2-3 tree</li>
<li>2-3-4 tree</li>
<li>B tree</li>
<li>Red-black tree</li>
<li>Skip lists</li>
<li>treaps </li>
</ul>
</li>
<li>Red-black proerties<ul>
<li>every node is either <em>red</em> or <em>black</em></li>
<li>root&amp; leaves &#xFF08;nil&#x2019;s) are all <em>black</em></li>
<li>every red node has black parent </li>
<li>all simple path from a ndoe X to a descendent leaf of x have same number of balck nodes = black height(does not count x itself)</li>
</ul>
</li>
<li>heght of read black tree<ul>
<li>red-black tree with n keys has height h &lt;= 2log(n+1) = O(log(n))</li>
<li>leaves = n+1 ( in either tree)</li>
</ul>
</li>
<li>Corollary Quereies<ul>
<li>search min O(logn)</li>
<li>search max O(logn)</li>
<li>successor O(logn)</li>
<li>prodecessor O(logn)</li>
</ul>
</li>
<li>Update ( insert &amp; delete)<ul>
<li>color change</li>
<li>reconstructe of links<ul>
<li>rotation (zig-zag)</li>
</ul>
</li>
<li>RB- insert <ul>
<li>find the position -&gt; create a leaf -&gt; get a color  (property 3 might be a problem)<ul>
<li>move violation up to the tree via recoloring until we can fix violation by rotation &amp; recoloring </li>
</ul>
</li>
<li>tree-insert(T,x)</li>
<li>color[x]-PED</li>
<li>while x is red and not at root<ul>
<li>case 1: x&#x2019;s grandparent&#x2019;s left child  57:30 video</li>
<li>case 2: see video</li>
<li>case 3: see video</li>
</ul>
</li>
<li>O(logn) time total</li>
<li>O(1) time rotation(rotation is expensive)</li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>

        
            
        
    </div>
    <div class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">TAGGED IN</span><br/>
                
    <a class="tag tag--primary tag--small t-link" href="/tags/algorithm-design/">algorithm design</a>

            </div>
        
        <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2015/09/17/movie-booklist/"  data-tooltip="movie_booklist">
                
                    <i class="fa fa-angle-left"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                </a>
            </li>
            <li class="post-action">
                
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2015/09/05/latexLearning/" data-tooltip="latexLearning">
                
                    <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                    <i class="fa fa-angle-right"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=http://lbting.com/2015/09/07/15650StudyingNote/">
                <i class="fa fa-google-plus"></i>
            </a>
        </li>
        <li class="post-action">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=http://lbting.com/2015/09/07/15650StudyingNote/">
                <i class="fa fa-facebook-official"></i>
            </a>
        </li>
        <li class="post-action">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=http://lbting.com/2015/09/07/15650StudyingNote/">
                <i class="fa fa-twitter"></i>
            </a>
        </li>
        
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" href="#disqus_thread">
                    <i class="fa fa-comment-o"></i>
                </a>
            </li>
        
    </ul>
</div>


        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2018 LBTING. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="1">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2015/09/17/movie-booklist/"  data-tooltip="movie_booklist">
                
                    <i class="fa fa-angle-left"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                </a>
            </li>
            <li class="post-action">
                
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2015/09/05/latexLearning/" data-tooltip="latexLearning">
                
                    <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                    <i class="fa fa-angle-right"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=http://lbting.com/2015/09/07/15650StudyingNote/">
                <i class="fa fa-google-plus"></i>
            </a>
        </li>
        <li class="post-action">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=http://lbting.com/2015/09/07/15650StudyingNote/">
                <i class="fa fa-facebook-official"></i>
            </a>
        </li>
        <li class="post-action">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=http://lbting.com/2015/09/07/15650StudyingNote/">
                <i class="fa fa-twitter"></i>
            </a>
        </li>
        
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" href="#disqus_thread">
                    <i class="fa fa-comment-o"></i>
                </a>
            </li>
        
    </ul>
</div>


                </div>
            
        </div>
        <div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-remove"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/42.jpg"/>
        
            <h4 id="about-card-name">LBTING</h4>
        
            <h5 id="about-card-bio"><p>Theyre both convinced that a sudden passion joined them.Such certainty is beautiful.But uncertainty is more beautiful still.</p>
</h5>
        
        
            <h5 id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>R&amp;D Engineer</p>

            </h5>
        
        
            <h5 id="about-card-location">
                <i class="fa fa-map-marker"></i>
                <br/>
                Albany USA
            </h5>
        
    </div>
</div>
        <div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
    </body>
    <!--SCRIPTS-->
<script src="/assets/js/script.min.js"></script>
<!--SCRIPTS END-->



</html>
